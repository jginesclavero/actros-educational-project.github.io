<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[RSS Feed]]></title><description><![CDATA[Center for Advanced Training on Robotics and %TOPICS%]]></description><link>https://actros-educational-project.github.io</link><generator>GatsbyJS</generator><lastBuildDate>Mon, 27 Jul 2020 10:13:05 GMT</lastBuildDate><item><title><![CDATA[ROS Course]]></title><description><![CDATA[Robot Operating System (ROS) Is the most used software around the world for robot programming. Since its beginnings, in 2006, its usage has been extended unstoppably. Nowadays, it is the standard in the robotic world.]]></description><link>https://actros-educational-project.github.io/ros</link><guid isPermaLink="false">https://actros-educational-project.github.io/ros</guid><pubDate>Fri, 10 Jul 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Robot Operating System (ROS) Is the most used software around the world for robot programming. Since its beginnings, in 2006, its usage has been extended unstoppably. Nowadays, it is the standard in the robotic world. It is a main tool in the investigation field and it is an essential requirement to be able to access the working world in any job related to the robotic.&lt;/p&gt;
&lt;p&gt;ROS is an ** open source ** robot programming framework, made up of a collection of libraries and tools. It defines a distributed architecture to create complex software for robots efficiently and strongly. With ROS, software for most of the robots that exist can be developed (Nao, Pepper, PR2, Baxter, Kobuki, Turtlebot, AR-Drone, Lego NXT, Bebop Drone, RB-1…). Also, you can use any sensor (LIDAR, cameras, RGB-D sensors…) or actuators like robotic arms.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[ROS2 Course]]></title><description><![CDATA[With the ROS2 release, a new system with much more advanced characteristics is raised and it will be the new standard in robotic software development in the industry.]]></description><link>https://actros-educational-project.github.io/ros2</link><guid isPermaLink="false">https://actros-educational-project.github.io/ros2</guid><pubDate>Thu, 09 Jul 2020 00:00:00 GMT</pubDate><content:encoded>&lt;h2 id=&quot;description&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#description&quot; aria-label=&quot;description permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Description&lt;/h2&gt;
&lt;p&gt;ROS (Robot Operating System), today, is the standard in the robotics area. That is why research in this area is essential and it is an very important requirement to be able to access the working world in any job related to robotics. Now, with the ROS2 release, a new system with much more advanced characteristics is raised and it will be the new standard in robotic software development in the industry.&lt;/p&gt;
&lt;h2 id=&quot;course-targets&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#course-targets&quot; aria-label=&quot;course targets permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Course Targets&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Differences between ROS and ROS2&lt;/li&gt;
&lt;li&gt;Main concepts about ROS2&lt;/li&gt;
&lt;li&gt;ROS2&apos;s main libraries and tools.&lt;/li&gt;
&lt;li&gt;ROS2 deployment on different devices.&lt;/li&gt;
&lt;li&gt;ROS2 Security.&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[Navigation Course]]></title><description><![CDATA[The ROS/ROS2 navigation stack is one of its main packages and it allow to give a robot basic capacities of movement in an easy way]]></description><link>https://actros-educational-project.github.io/navigation</link><guid isPermaLink="false">https://actros-educational-project.github.io/navigation</guid><pubDate>Wed, 08 Jul 2020 00:00:00 GMT</pubDate><content:encoded>&lt;h2 id=&quot;description&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#description&quot; aria-label=&quot;description permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Description&lt;/h2&gt;
&lt;p&gt;The ROS/ROS2 navigation stack is one of its main packages and it allow to give a robot basic capacities of movement in an easy way. Also, the navigation package provide us a high flexibility, making it perfect for ensuring a fast deployment of the robot in an industrial or domestic environment.&lt;/p&gt;
&lt;h2 id=&quot;course-targets&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#course-targets&quot; aria-label=&quot;course targets permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Course Targets&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Main concepts about ROS/ROS2 navigation.&lt;/li&gt;
&lt;li&gt;Maps creation, SLAM.&lt;/li&gt;
&lt;li&gt;Localization system knowledge.&lt;/li&gt;
&lt;li&gt;Parameters usage for adopting the system to the environment.&lt;/li&gt;
&lt;li&gt;Trials on simulated and real robots.&lt;/li&gt;
&lt;/ul&gt;
&lt;iframe width=&quot;100%&quot; height=&quot;485&quot; src=&quot;https://www.youtube.com/embed/OklxMhdDfe0&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;</content:encoded></item><item><title><![CDATA[Perception]]></title><description><![CDATA[Sensors are a data source very important for robots. Because of them, they can recognize its environment and get information very valious about it.]]></description><link>https://actros-educational-project.github.io/perception</link><guid isPermaLink="false">https://actros-educational-project.github.io/perception</guid><pubDate>Tue, 07 Jul 2020 00:00:00 GMT</pubDate><content:encoded>&lt;h2 id=&quot;description&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#description&quot; aria-label=&quot;description permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Description&lt;/h2&gt;
&lt;p&gt;Sensors are a data source very important for robots. Because of them, they can recognize its environment and get information very valious about it.&lt;/p&gt;
&lt;p&gt;Specifically, the camera is the most complex sensor that exist and, at the same time, it provide a great flow of data. Thank of that, useful algorithms can be elaborated for robot environment recognition. For example, &lt;strong&gt;Neural Networks&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&quot;course-targets&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#course-targets&quot; aria-label=&quot;course targets permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Course Targets&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Most common robot sensors types.&lt;/li&gt;
&lt;li&gt;Getting data by the sensors.&lt;/li&gt;
&lt;li&gt;2D processing of cameras information with OpenCV.&lt;/li&gt;
&lt;li&gt;3D sensorial data management.&lt;/li&gt;
&lt;li&gt;3D processing of RGBD cameras information with &lt;strong&gt;PCL&lt;/strong&gt; (Point Cloud Library).&lt;/li&gt;
&lt;li&gt;Trials with simulated and real robots.&lt;/li&gt;
&lt;/ul&gt;
&lt;iframe width=&quot;100%&quot; height=&quot;485&quot; src=&quot;https://www.youtube.com/embed/262S-Z1o4tw&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;</content:encoded></item><item><title><![CDATA[Deep Learning]]></title><description><![CDATA[Deep Learning is one of the most popular areas in the robotics field. Researchs in this area have got awesome results in fields like Natural Language Processing and Computer Vision.]]></description><link>https://actros-educational-project.github.io/deep_learning</link><guid isPermaLink="false">https://actros-educational-project.github.io/deep_learning</guid><pubDate>Mon, 06 Jul 2020 00:00:00 GMT</pubDate><content:encoded>&lt;h2 id=&quot;description&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#description&quot; aria-label=&quot;description permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Description&lt;/h2&gt;
&lt;p&gt;Deep Learning is one of the most popular areas in the robotics field. Researchs in this area have got awesome results in fields like &lt;strong&gt;Natural Language Processing&lt;/strong&gt; and &lt;strong&gt;Computer Vision&lt;/strong&gt; using knowledge methods based on how human nervous system works, using differents stages that constitute different processing levels whose purpose is the characteristics extraction of specific objects.&lt;/p&gt;
&lt;h2 id=&quot;course-targets&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#course-targets&quot; aria-label=&quot;course targets permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Course Targets&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Mathematics main concepts of Deep Learning systems.&lt;/li&gt;
&lt;li&gt;CUDA configuration.&lt;/li&gt;
&lt;li&gt;Deep Learning systems integration with ROS/ROS2.&lt;/li&gt;
&lt;li&gt;Trials with simulated and real robots.&lt;/li&gt;
&lt;/ul&gt;
&lt;iframe width=&quot;100%&quot; height=&quot;485&quot; src=&quot;https://www.youtube.com/embed/HMWnCnnnQZg&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;</content:encoded></item></channel></rss>